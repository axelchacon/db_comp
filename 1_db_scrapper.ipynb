{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB_COMP Web Scraper\n",
    "\n",
    "## Overview\n",
    "This code contains a web scraper for the [DB_COMP](https://db-comp.eu/) website, which hosts decisions issued by the European Commission on Competition Law and the Digital Markets Act. The scraper is designed to extract and process relevant information from the website, providing an efficient way to collect and analyze these decisions.\n",
    "\n",
    "## Features\n",
    "- Scrapes decision documents from the DB_COMP website.\n",
    "- Extracts key information such as decision dates, titles and URLs.\n",
    "- Stores the extracted data in a structured format for easy analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "\n",
    "import time \n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://db-comp.eu/\")\n",
    "time.sleep(4)\n",
    "driver.find_element(By.LINK_TEXT, \"Accept all\").click()\n",
    "driver.find_element(By.ID, \"1\").click()\n",
    "driver.find_element(By.ID, \"2\").click()\n",
    "driver.find_element(By.ID, \"3\").click()\n",
    "driver.find_element(By.ID, \"5\").click()\n",
    "driver.find_element(By.ID, \"plgslt_Slot_Main_3_search\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_link = []\n",
    "l_titulo = []\n",
    "l_categories = []\n",
    "l_release_date = []\n",
    "\n",
    "for i in range(69):\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    table = soup.find(\"div\", {\"id\": \"plgslt_Slot_Main_3_results\"})\n",
    "\n",
    "    for row in table.findAll('div', class_='result'):\n",
    "        link = row.a['href']\n",
    "        titulo = row.find('p', class_='title').text.strip() \n",
    "        categories = row.find('div', class_='categories').text.strip()\n",
    "        release_date = row.find('p', class_='release_date').text.strip()\n",
    "\n",
    "        l_link.append(link)\n",
    "        l_titulo.append(titulo)\n",
    "        l_categories.append(categories)\n",
    "        l_release_date.append(release_date)\n",
    "        \n",
    "    driver.find_element(By.LINK_TEXT, \"Next\").click()\n",
    "    time.sleep(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(l_titulo, l_categories, l_release_date, l_link)),\n",
    "                                    columns=['Title', 'Category', 'Release Date', 'Link'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do some processing to adapt the format of the release date\n",
    "\n",
    "df['Release Date'] = df['Release Date'].str.replace('Date: ', '')\n",
    "\n",
    "def transform_date(date_str):\n",
    "    # Define the regex pattern to match the date format\n",
    "    pattern = r\"(\\d{1,2})\\s([A-Za-z]+)\\s(\\d{4})\"\n",
    "    \n",
    "    # Dictionary to map month names to their numeric values\n",
    "    month_map = {\n",
    "        'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04',\n",
    "        'May': '05', 'Jun': '06', 'Jul': '07', 'Aug': '08',\n",
    "        'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'\n",
    "    }\n",
    "    \n",
    "    # Function to replace the date string\n",
    "    def replace_date(match):\n",
    "        day = match.group(1).zfill(2)  # Zero-pad day if necessary\n",
    "        month = month_map[match.group(2)[:3]]  # Get the month number from the map\n",
    "        year = match.group(3)\n",
    "        return f\"{day}/{month}/{year}\"\n",
    "    \n",
    "    # Use re.sub to replace the date format\n",
    "    return re.sub(pattern, replace_date, date_str)\n",
    "\n",
    "df['Release Date'] = df['Release Date'].apply(transform_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"D:\\Proyectos\\db_comp\\database.csv\", index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
